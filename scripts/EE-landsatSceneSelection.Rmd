---
title: "landsatSceneFromEE"
author: "Anna Talucci"
date: "2024-04-23"
output: html_document
---



```{r}
library(tidyverse)
```
```{r}
direScenes = read_csv('../outputs/landsatScenes/CanadaDIREPriority.csv')
```
```{r}
list = list.files(path="../data/landsatScenes", pattern ="csv$", full.name=TRUE)
```

```{r}
list
```

```{r}
names(list) = tools::file_path_sans_ext(basename(list))
```

Function to read in csv and bind rows
```{r}
readCombine = function(list){
  purrr::map(list, read.csv) %>%
    map2(names(.), ~mutate(.x, fileName=.y)) %>%
    bind_rows()
}
```

```{r}
df = list %>% readCombine() %>% dplyr::select(!.geo)
```

```{r}
df
```

SK Albedo Scenes

```{r}
(skAlbedo  = df %>% filter(!is.na(mean)) %>% dplyr::select(ACQDayL7, ACQDayL8, ISO_A2, PATH, ROW, PR, mean, fileName ))
```

```{r}
unique(skAlbedo$PR)
cat(paste0(sprintf('%s', unique(skAlbedo$PR)), collapse='","'))
```

```{r}

sk_target = c("45017","45018","45019","36017","36018","36019","36020","36021","36022","36023","36024","43017","43018","43019","43020","43021","34018","34019","34020","34021","34022","34023","34024","41017","41018","41019","41020","41021","41022","41023","41024","39017","39018","39019","39020","39021","39022","39023","39024","37017","37018","37019","37020","37021","37022","37023","37024","44017","44018","44019","44020","44021","35018","35019","35020","35021","35022","35023","35024","42017","42018","42019","42020","42021","42022","42023","33020","33021","33022","33023","33024","40017","40018","40019","40020","40021","40022","40023","40024","38017","38018","38019","38020","38021","38022","38023","38024")
```

Remove Albedo select from df
AK Data
```{r}
(dfAK = df %>% filter(fileName!='LandsatSceneMeanAlbSK') %>% filter(ISO_A2=="US") %>%
   mutate(maxYear = ifelse(fileName == "LandsatScenePixCtReburnAK2013", "2013",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2014", "2014",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2015", "2015",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2016", "2016",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2017", "2017",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2018", "2018",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2019", "2019",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2020", "2020", "2021"))))))))) %>% 
    mutate(albStartYr = ifelse(fileName == "LandsatScenePixCtReburnAK2013", "2014",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2014", "2015",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2015", "2016",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2016", "2017",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2017", "2018",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2018", "2019",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2019", "2020",
                    ifelse(fileName == "LandsatScenePixCtReburnAK2020", "2021", "2022"))))))))) %>% 
   dplyr::select(ACQDayL7, ACQDayL8, ISO_A2, PATH, ROW, PR, count, maxYear, albStartYr) %>%
   filter(count >0) %>%
   #filter(albStartYr !="2018") %>% 
   filter(count > 500) # remove 9
   
)
```

```{r}
n_distinct(dfAK$PR)
min(dfAK$count)
max(dfAK$count)
mean(dfAK$count)
median(dfAK$count)
```

## summarize PR and years
```{r}
dfAK %>% group_by(maxYear, albStartYr, PR) %>%
  summarize(meanCt = mean(count))
```

## Unique Row Path with years of interest as list

```{r}
( akPRYr = dfAK %>%
      group_by(PR, PATH, ROW) %>% 
      summarise(maxYear = toString(unique(maxYear)),
                albStartYr = min(albStartYr)) 
)
```

```{r}
write.csv(akPRYr, '../outputs/landsatScenes/LC1ScenesOfInterestAK.csv', row.names=F)

```

## Generate the additonal ROW PATH needed to have for Albedo Processing

```{r}
( additionalRows = akPRYr %>% 
  group_by(PR) %>%
  mutate(newROWplus = (ROW+1), 
         newROWminus = (ROW-1)) %>%
  pivot_longer(cols = starts_with("new"),
    names_to = "newRow",
    values_to = "ROWNew",
    values_drop_na = TRUE
  ) %>%
  mutate(ROW = paste0("0", ROWNew),
         PRNew = paste0(PATH, ROW)) %>%
    ungroup() %>%
  dplyr::select(PRNew, PATH, ROWNew, maxYear) %>%
    rename(PR=PRNew, ROW= ROWNew) %>%
    mutate(PR = as.integer(PR))
)
```

### Bind rows additional plus original
```{r}
(ak = bind_rows(akPRYr, additionalRows) %>%
   distinct() %>%
  arrange(PR) %>%
  group_by(PR, PATH, ROW) %>% 
      summarise(maxYear = toString(unique(maxYear))) %>%
  dplyr::select(PR, PATH, ROW, maxYear)%>%
    mutate(location = "AK")
                )
```




# Processing for Canada

```{r}
(dfCA = df %>% filter(fileName!='LandsatSceneMeanAlbSK') %>% filter(ISO_A2=="CA") %>%
   mutate(maxYear = ifelse(fileName == "LandsatScenePixCtReburnCA2013", "2013",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2014", "2014",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2015", "2015",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2016", "2016",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2017", "2017",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2018", "2018",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2019", "2019",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2020", "2020", "2021"))))))))) %>% 
   mutate(albStartYr = ifelse(fileName == "LandsatScenePixCtReburnCA2013", "2014",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2014", "2015",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2015", "2016",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2016", "2017",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2017", "2018",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2018", "2019",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2019", "2020",
                    ifelse(fileName == "LandsatScenePixCtReburnCA2020", "2021", "2022"))))))))) %>% 
   dplyr::select(ACQDayL7, ACQDayL8, ISO_A2, PATH, ROW, PR, count, maxYear, albStartYr) %>%
   filter(count >0) %>%
   filter(!PR %in% sk_target) %>%
   #filter(albStartYr !="2018") %>% 
   filter(count > 500) # remove 83
)
```



```{r}
n_distinct(dfCA$PR)
min(dfCA$count)
max(dfCA$count)
mean(dfCA$count)
median(dfCA$count)
```

```{r}
( caPRYr = dfCA %>%
      group_by(PR, PATH, ROW) %>% 
      summarise(maxYear = toString(unique(maxYear))) 
)
```
```{r}
write.csv(caPRYr, '../outputs/landsatScenes/LC1ScenesOfInterestCan.csv', row.names=F)

```

## Generate the additonal ROW PATH needed to have for Albedo Processing

```{r}
( additionalRows = caPRYr %>% 
  group_by(PR) %>%
  mutate(newROWplus = (ROW+1), 
         newROWminus = (ROW-1)) %>%
  pivot_longer(cols = starts_with("new"),
    names_to = "newRow",
    values_to = "ROWNew",
    values_drop_na = TRUE
  ) %>%
  mutate(ROW = paste0("0", ROWNew),
         PRNew = paste0(PATH, ROW)) %>%
    ungroup() %>%
  dplyr::select(PRNew, PATH, ROWNew, maxYear) %>%
    rename(PR=PRNew, ROW= ROWNew) %>%
    mutate(PR = as.integer(PR))
)
```

```{r}
( direScenes = direScenes %>% mutate(DIRE = "DIRE") )
```

```{r}
( priority = caPRYr %>% 
    full_join(direScenes, by=c("PATH", "ROW")) %>% 
    select(-PR.y) %>% rename(PR=PR.x) %>% 
    mutate_at(vars(DIRE), ~replace(., is.na(.), "other")) %>% 
    mutate(priority = ifelse(DIRE == "DIRE", "1", 
                      ifelse(DIRE =="other", "2", "3"))) )
```
```{r}
priority %>% filter(priority == "1")
priority %>% filter(priority == "2")
priority %>% filter(priority == "3")
```
### Bind rows additional plus original

```{r}
(ca = bind_rows(caPRYr, additionalRows) %>%
   distinct() %>%
  arrange(PR) %>%
  group_by(PR, PATH, ROW) %>% 
      summarise(maxYear = toString(unique(maxYear))) %>%
  dplyr::select(PR, PATH, ROW, maxYear)%>%
    mutate(location = "CA")
                )
```


# Save as csv

```{r}
write.csv(ak, '../outputs/landsatScenes/LandsatCol1ScenesAK.csv', row.names=F)
write.csv(ca, '../outputs/landsatScenes/LandsatCol1ScenesCA.csv', row.names=F)
```
